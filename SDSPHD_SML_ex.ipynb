{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SDSPHD_UML_ex.ipynb",
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMR95vetF93icnhljW5WOU0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daniel-hain/CALDISS_WS_exploratory_analysis/blob/master/SDSPHD_SML_ex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSGD9uQfoWcF"
      },
      "source": [
        "# Unsupervised ML with Penguins\n",
        "\n",
        "The palmer penguin dataset is excellent for EDA and UML. It contains different measures for 3 species of closely related penguins from several islands in Antarctica.\n",
        "\n",
        "Let's have a look:\n",
        "\n",
        "Penguin datast: https://github.com/allisonhorst/palmerpenguins\n",
        "![](https://github.com/allisonhorst/palmerpenguins/raw/master/man/figures/lter_penguins.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oADGIlNMpC6J"
      },
      "source": [
        "![](https://github.com/allisonhorst/palmerpenguins/raw/master/man/figures/culmen_depth.png)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvCwRO50os4t"
      },
      "source": [
        "# Get the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqOymkJwo__d"
      },
      "source": [
        "# standard packaging\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set(color_codes=True, rc={'figure.figsize':(10,8)})\n",
        "\n",
        "from IPython.display import HTML #Youtube embed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHCJQBRZouiX"
      },
      "source": [
        "# load the dataset from GitHub - original source\n",
        "\n",
        "penguins = pd.read_csv(\"https://github.com/allisonhorst/palmerpenguins/raw/5b5891f01b52ae26ad8cb9755ec93672f49328a8/data/penguins_size.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHpULRXbpJzk"
      },
      "source": [
        "# Your task\n",
        "\n",
        "1. Inspect the dat with some of the standard functions you learned so far (desc, info etc.). What do we have here?\n",
        "2. Likewise, use some standard visualizations (eg. from seaborn) to express some properties of the data\n",
        "3. Apply stanbdard preprocessing (eg. missing values, scaling, outliers, one-hot-encoding)\n",
        "4. Split the data in a train & test sample\n",
        "5. Fit a classification model (target outcome = 'species') on the training data, and evaluate its performance on the test data.\n",
        "   * Use first a logistic regression to do so.\n",
        "   * Then, use 2-3 more complex model classes of your choice."
      ]
    }
  ]
}